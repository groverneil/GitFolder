{"ast":null,"code":"var _jsxFileName = \"/Users/neilgrover/Documents/NodeJs/udemy-tutorial/multi-page-testing/src/Pages/projects.js\";\nimport ContentBox from \"../Components/content-b\";\nimport NavigationBar from \"../Components/nav\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction Projects() {\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"Projects\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 9,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(NavigationBar, {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 10,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(ContentBox, {\n      title: \"Webscrapping Project\",\n      content: \"This is a webscrapping task that navigates to indeed.com and scrapes python interships programs. The source code is written in python based on the scraping libraries pof beautiful soup and Scrapy. The task is automated to run daily using Cron (MacOS). The picture on the right shows the sample output of the program.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 11,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 8,\n    columnNumber: 9\n  }, this);\n}\n_c = Projects;\nexport default Projects;\nvar _c;\n$RefreshReg$(_c, \"Projects\");","map":{"version":3,"names":["ContentBox","NavigationBar","Projects"],"sources":["/Users/neilgrover/Documents/NodeJs/udemy-tutorial/multi-page-testing/src/Pages/projects.js"],"sourcesContent":["import ContentBox from \"../Components/content-b\"\nimport NavigationBar from \"../Components/nav\"\n\nfunction Projects(){\n\n    return (\n\n        <div>\n            <h1>Projects</h1>\n            <NavigationBar/>\n            <ContentBox title = \"Webscrapping Project\" content = \"This is a webscrapping task that navigates to indeed.com and scrapes python interships programs. The source code is written in python based on the scraping libraries pof beautiful soup and Scrapy. The task is automated to run daily using Cron (MacOS). The picture on the right shows the sample output of the program.\"/>\n        </div>\n    )\n\n}\n\nexport default Projects"],"mappings":";AAAA,OAAOA,UAAU,MAAM,yBAAyB;AAChD,OAAOC,aAAa,MAAM,mBAAmB;AAAA;AAE7C,SAASC,QAAQ,GAAE;EAEf,oBAEI;IAAA,wBACI;MAAA;IAAA;MAAA;MAAA;MAAA;IAAA,QAAiB,eACjB,QAAC,aAAa;MAAA;MAAA;MAAA;IAAA,QAAE,eAChB,QAAC,UAAU;MAAC,KAAK,EAAG,sBAAsB;MAAC,OAAO,EAAG;IAA8T;MAAA;MAAA;MAAA;IAAA,QAAE;EAAA;IAAA;IAAA;IAAA;EAAA,QACnX;AAGd;AAAC,KAXQA,QAAQ;AAajB,eAAeA,QAAQ;AAAA;AAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}